{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "45ddad59-4f3a-4163-b135-edccab102d84",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 17767,
     "status": "ok",
     "timestamp": 1727115264409,
     "user": {
      "displayName": "Bruno Vogel",
      "userId": "14599946058062416327"
     },
     "user_tz": 180
    },
    "id": "45ddad59-4f3a-4163-b135-edccab102d84",
    "outputId": "3f660397-38f6-4e93-8455-a06e6591c3af"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: pycryptodome in c:\\users\\bruno\\appdata\\roaming\\python\\python312\\site-packages (3.20.0)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: numpy in d:\\anaconda3\\lib\\site-packages (1.26.4)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: cryptography in d:\\anaconda3\\lib\\site-packages (43.0.0)\n",
      "Requirement already satisfied: cffi>=1.12 in d:\\anaconda3\\lib\\site-packages (from cryptography) (1.16.0)\n",
      "Requirement already satisfied: pycparser in d:\\anaconda3\\lib\\site-packages (from cffi>=1.12->cryptography) (2.21)\n"
     ]
    }
   ],
   "source": [
    "!pip install pycryptodome numpy cryptography psutil memory-profiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b3d6b4bd-a919-45e9-aa49-c7d17041d50b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selecione o teste que deseja executar:\n",
      "1: test_ccakem.py\n",
      "2: test_cpake.py\n",
      "3: test_indcpa.py\n",
      "4: test_ntt.py\n",
      "5: test_prf.py\n",
      "6: test_util.py\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Digite o número do teste:  6\n",
      "Quantas vezes deseja executar o teste para estresse?  100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execução 1 de 100\n",
      "Execução 2 de 100\n",
      "Execução 3 de 100\n",
      "Execução 4 de 100\n",
      "Execução 5 de 100\n",
      "Execução 6 de 100\n",
      "Execução 7 de 100\n",
      "Execução 8 de 100\n",
      "Execução 9 de 100\n",
      "Execução 10 de 100\n",
      "Execução 11 de 100\n",
      "Execução 12 de 100\n",
      "Execução 13 de 100\n",
      "Execução 14 de 100\n",
      "Execução 15 de 100\n",
      "Execução 16 de 100\n",
      "Execução 17 de 100\n",
      "Execução 18 de 100\n",
      "Execução 19 de 100\n",
      "Execução 20 de 100\n",
      "Execução 21 de 100\n",
      "Execução 22 de 100\n",
      "Execução 23 de 100\n",
      "Execução 24 de 100\n",
      "Execução 25 de 100\n",
      "Execução 26 de 100\n",
      "Execução 27 de 100\n",
      "Execução 28 de 100\n",
      "Execução 29 de 100\n",
      "Execução 30 de 100\n",
      "Execução 31 de 100\n",
      "Execução 32 de 100\n",
      "Execução 33 de 100\n",
      "Execução 34 de 100\n",
      "Execução 35 de 100\n",
      "Execução 36 de 100\n",
      "Execução 37 de 100\n",
      "Execução 38 de 100\n",
      "Execução 39 de 100\n",
      "Execução 40 de 100\n",
      "Execução 41 de 100\n",
      "Execução 42 de 100\n",
      "Execução 43 de 100\n",
      "Execução 44 de 100\n",
      "Execução 45 de 100\n",
      "Execução 46 de 100\n",
      "Execução 47 de 100\n",
      "Execução 48 de 100\n",
      "Execução 49 de 100\n",
      "Execução 50 de 100\n",
      "Execução 51 de 100\n",
      "Execução 52 de 100\n",
      "Execução 53 de 100\n",
      "Execução 54 de 100\n",
      "Execução 55 de 100\n",
      "Execução 56 de 100\n",
      "Execução 57 de 100\n",
      "Execução 58 de 100\n",
      "Execução 59 de 100\n",
      "Execução 60 de 100\n",
      "Execução 61 de 100\n",
      "Execução 62 de 100\n",
      "Execução 63 de 100\n",
      "Execução 64 de 100\n",
      "Execução 65 de 100\n",
      "Execução 66 de 100\n",
      "Execução 67 de 100\n",
      "Execução 68 de 100\n",
      "Execução 69 de 100\n",
      "Execução 70 de 100\n",
      "Execução 71 de 100\n",
      "Execução 72 de 100\n",
      "Execução 73 de 100\n",
      "Execução 74 de 100\n",
      "Execução 75 de 100\n",
      "Execução 76 de 100\n",
      "Execução 77 de 100\n",
      "Execução 78 de 100\n",
      "Execução 79 de 100\n",
      "Execução 80 de 100\n",
      "Execução 81 de 100\n",
      "Execução 82 de 100\n",
      "Execução 83 de 100\n",
      "Execução 84 de 100\n",
      "Execução 85 de 100\n",
      "Execução 86 de 100\n",
      "Execução 87 de 100\n",
      "Execução 88 de 100\n",
      "Execução 89 de 100\n",
      "Execução 90 de 100\n",
      "Execução 91 de 100\n",
      "Execução 92 de 100\n",
      "Execução 93 de 100\n",
      "Execução 94 de 100\n",
      "Execução 95 de 100\n",
      "Execução 96 de 100\n",
      "Execução 97 de 100\n",
      "Execução 98 de 100\n",
      "Execução 99 de 100\n",
      "Execução 100 de 100\n",
      "\n",
      "Resultados após 100 execuções do script test_util.py:\n",
      "Tempo total de execução: 15.85 segundos\n",
      "Tempo médio de execução: 0.16 segundos\n",
      "Memória máxima utilizada: 0.00 MiB\n",
      "Memória média utilizada: -0.00 MiB\n",
      "CPU máxima utilizada: 1.25%\n",
      "CPU média utilizada: 0.16%\n",
      "\n",
      "Resultado da última execução:\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import psutil\n",
    "import subprocess\n",
    "import os\n",
    "\n",
    "# Função para medir o tempo, processamento e memória\n",
    "def measure_performance(script_name, iterations, output_file):\n",
    "    total_time = 0\n",
    "    total_memory = 0\n",
    "    total_cpu = 0\n",
    "    max_memory = 0\n",
    "    max_cpu = 0\n",
    "\n",
    "    with open(output_file, 'a') as f:\n",
    "        # Escreve o cabeçalho no arquivo\n",
    "        f.write(f\"\\n\\nTeste do script: {script_name}\\n\")\n",
    "        f.write(f\"Número de execuções: {iterations}\\n\")\n",
    "        f.write(\"=============================================\\n\")\n",
    "\n",
    "        for i in range(iterations):\n",
    "            print(f\"Execução {i + 1} de {iterations}\")\n",
    "\n",
    "            # Início da medição de tempo\n",
    "            start_time = time.time()\n",
    "\n",
    "            # Memória e uso de CPU iniciais\n",
    "            process = psutil.Process(os.getpid())\n",
    "            start_memory = process.memory_info().rss / 1024 / 1024  # Memória em MiB\n",
    "            start_cpu = process.cpu_percent(interval=None) / psutil.cpu_count(logical=False)\n",
    "\n",
    "            # Executa o script Python\n",
    "            result = subprocess.run(['python3', script_name], capture_output=True, text=True)\n",
    "\n",
    "            # Final da medição de tempo\n",
    "            end_time = time.time()\n",
    "\n",
    "            # Memória e uso de CPU finais\n",
    "            end_memory = process.memory_info().rss / 1024 / 1024  # Memória em MiB\n",
    "            end_cpu = process.cpu_percent(interval=None) / psutil.cpu_count(logical=False)\n",
    "\n",
    "            # Acumula os resultados\n",
    "            elapsed_time = end_time - start_time\n",
    "            memory_used = end_memory - start_memory\n",
    "            cpu_used = end_cpu - start_cpu\n",
    "\n",
    "            # Acumula os resultados gerais\n",
    "            total_time += elapsed_time\n",
    "            total_memory += memory_used\n",
    "            total_cpu += cpu_used\n",
    "\n",
    "            # Verifica máximos de CPU e Memória\n",
    "            max_memory = max(max_memory, memory_used)\n",
    "            max_cpu = max(max_cpu, cpu_used)\n",
    "\n",
    "            # Escreve os resultados da execução atual no arquivo\n",
    "            f.write(f\"Execução {i + 1}:\\n\")\n",
    "            f.write(f\"  Tempo de execução: {elapsed_time:.2f} segundos\\n\")\n",
    "            f.write(f\"  Memória utilizada: {memory_used:.2f} MiB\\n\")\n",
    "            f.write(f\"  CPU utilizada: {cpu_used:.2f}%\\n\")\n",
    "            f.write(\"---------------------------------------------\\n\")\n",
    "\n",
    "        # Resultados médios\n",
    "        avg_time = total_time / iterations\n",
    "        avg_memory = total_memory / iterations\n",
    "        avg_cpu = total_cpu / iterations\n",
    "\n",
    "        # Escreve o resumo dos resultados no arquivo\n",
    "        f.write(f\"\\nResultados após {iterations} execuções:\\n\")\n",
    "        f.write(f\"Tempo total de execução: {total_time:.2f} segundos\\n\")\n",
    "        f.write(f\"Tempo médio de execução: {avg_time:.2f} segundos\\n\")\n",
    "        f.write(f\"Memória máxima utilizada: {max_memory:.2f} MiB\\n\")\n",
    "        f.write(f\"Memória média utilizada: {avg_memory:.2f} MiB\\n\")\n",
    "        f.write(f\"CPU máxima utilizada: {max_cpu:.2f}%\\n\")\n",
    "        f.write(f\"CPU média utilizada: {avg_cpu:.2f}%\\n\")\n",
    "        f.write(f\"\\nResultado da última execução:\\n{result.stdout}\\n\")\n",
    "        f.write(\"=============================================\\n\")\n",
    "\n",
    "    # Exibe os resultados no console também\n",
    "    print(f\"\\nResultados após {iterations} execuções do script {script_name}:\")\n",
    "    print(f\"Tempo total de execução: {total_time:.2f} segundos\")\n",
    "    print(f\"Tempo médio de execução: {avg_time:.2f} segundos\")\n",
    "    print(f\"Memória máxima utilizada: {max_memory:.2f} MiB\")\n",
    "    print(f\"Memória média utilizada: {avg_memory:.2f} MiB\")\n",
    "    print(f\"CPU máxima utilizada: {max_cpu:.2f}%\")\n",
    "    print(f\"CPU média utilizada: {avg_cpu:.2f}%\")\n",
    "    print(f\"\\nResultado da última execução:\\n{result.stdout}\")\n",
    "\n",
    "# Função principal para selecionar qual teste executar\n",
    "def main():\n",
    "    # Lista de scripts disponíveis\n",
    "    scripts = {\n",
    "        '1': 'test_ccakem.py',\n",
    "        '2': 'test_cpake.py',\n",
    "        '3': 'test_indcpa.py',\n",
    "        '4': 'test_ntt.py',\n",
    "        '5': 'test_prf.py',\n",
    "        '6': 'test_util.py'\n",
    "    }\n",
    "\n",
    "    # Exibe as opções para o usuário\n",
    "    print(\"Selecione o teste que deseja executar:\")\n",
    "    for key, value in scripts.items():\n",
    "        print(f\"{key}: {value}\")\n",
    "\n",
    "    # Recebe a escolha do usuário\n",
    "    choice = input(\"Digite o número do teste: \")\n",
    "\n",
    "    # Verifica se a escolha é válida\n",
    "    if choice in scripts:\n",
    "        # Pergunta quantas vezes o teste deve ser executado\n",
    "        try:\n",
    "            iterations = int(input(\"Quantas vezes deseja executar o teste para estresse? \"))\n",
    "        except ValueError:\n",
    "            print(\"Valor inválido. Usando 1 execução como padrão.\")\n",
    "            iterations = 1\n",
    "\n",
    "        # Define o arquivo de saída para salvar os resultados\n",
    "        output_file = 'benchmark_test_auto_results.txt'\n",
    "\n",
    "        # Executa o teste na quantidade solicitada\n",
    "        measure_performance(scripts[choice], iterations, output_file)\n",
    "    else:\n",
    "        print(\"Escolha inválida.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
